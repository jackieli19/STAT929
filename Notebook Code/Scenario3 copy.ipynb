{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import impyute as impy\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import datawig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtodf(filename, colname):\n",
    "    a=filename+'.txt'\n",
    "    data = pd.read_csv(a, sep=\",\", header=(0))\n",
    "    data.columns=['a','Date',colname]\n",
    "    data=data.drop('a',axis=1)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data.set_index('Date')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=readtodf('prod_target','Beer')\n",
    "prod_1=readtodf('prod_1','Car')\n",
    "prod_2=readtodf('prod_2','Steel')\n",
    "eng_1=readtodf('eng_1','Gas')\n",
    "eng_2=readtodf('eng_2','Electricity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('temp.txt', sep=\",\", header=(0))\n",
    "temp.columns=['num','year','month','Temp']\n",
    "temp=temp.drop('num',axis=1)\n",
    "temp['day']=1\n",
    "temp['Date']=pd.to_datetime(temp[['year', 'month', 'day']])\n",
    "temp=temp.drop(['year', 'month', 'day'],axis=1)\n",
    "temp = temp.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((435, 1), (369, 1), (435, 1), (435, 1), (435, 1), (581, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape,prod_1.shape,prod_2.shape, eng_1.shape,eng_2.shape,temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # creat dataframe version of merged data\n",
    "dfs = [target, prod_1, prod_2, eng_1,eng_2,temp]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True,how='left'), dfs)\n",
    "#df_final.to_csv('data_merged.csv')\n",
    "\n",
    "# creat numpy version of merged data\n",
    "np_final=np.array(df_final.values,dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beer</th>\n",
       "      <th>Car</th>\n",
       "      <th>Steel</th>\n",
       "      <th>Gas</th>\n",
       "      <th>Electricity</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956-01-01</th>\n",
       "      <td>93.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.9</td>\n",
       "      <td>1709</td>\n",
       "      <td>1254</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-02-01</th>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.1</td>\n",
       "      <td>1646</td>\n",
       "      <td>1290</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-03-01</th>\n",
       "      <td>95.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.8</td>\n",
       "      <td>1794</td>\n",
       "      <td>1379</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-04-01</th>\n",
       "      <td>77.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.9</td>\n",
       "      <td>1878</td>\n",
       "      <td>1346</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-05-01</th>\n",
       "      <td>70.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2173</td>\n",
       "      <td>1535</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Beer  Car  Steel   Gas  Electricity  Temp\n",
       "Date                                                 \n",
       "1956-01-01  93.2  NaN  196.9  1709         1254  25.1\n",
       "1956-02-01  96.0  NaN  192.1  1646         1290  25.3\n",
       "1956-03-01  95.2  NaN  201.8  1794         1379  24.9\n",
       "1956-04-01  77.1  NaN  186.9  1878         1346  23.9\n",
       "1956-05-01  70.9  NaN  218.0  2173         1535  19.4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Mice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multiple Imputation by Chained Equations (MICE) method is widely used in practice, which uses chain equations to create multiple imputations for variables of diferent types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_mice=impy.imputation.cs.mice(np_final)\n",
    "np.savetxt('./Imputation Results/imputation_mice.csv',ip_mice,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This method uses k-nearest neighbor to fInd similar samples and imputed unobserved data by weighted average of similar observations.\n",
    "- Basic idea: Impute array with a basic mean impute and then use the resulting complete array to construct a KDTree. Use this KDTree to compute nearest neighbours. After finding k nearest neighbours, take the weighted average of them. Basically, find the nearest row in terms of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_knn=impy.imputation.cs.fast_knn(np_final)\n",
    "np.savetxt('./Imputation Results/imputation_knn.csv',ip_knn,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.DataWig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Deep\" Learning for Missing Value Imputationin Tables with Non-Numerical Data\n",
    "- Details on the underlying model can be found in [Biessmann, Salinas et al. 2018](https://dl.acm.org/citation.cfm?id=3272005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['Car','Steel','Gas','Electricity','Temp'], # column(s) containing information about the column we want to impute\n",
    "    output_column='Beer', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Using LSTMs instead of bag-of-words\n",
    "# data_encoder_cols = [NumericalEncoder('Car'), NumericalEncoder('Steel'),NumericalEncoder('Gas'),\\\n",
    "#                     NumericalEncoder('Electricity'),NumericalEncoder('Temp')]\n",
    "# label_encoder_cols = [NumericalEncoder('Beer')]\n",
    "# data_featurizer_cols = [LSTMFeaturizer('Car'), LSTMFeaturizer('Steel'),LSTMFeaturizer('Gas'),\\\n",
    "#                     LSTMFeaturizer('Electricity'),LSTMFeaturizer('Temp')]\n",
    "\n",
    "# imputer = Imputer(\n",
    "#     data_featurizers=data_featurizer_cols,\n",
    "#     label_encoders=label_encoder_cols,\n",
    "#     data_encoders=data_encoder_cols,\n",
    "#     output_path='imputer_model'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-20 23:21:52,585 [INFO]  Assuming 5 numeric input columns: Car, Steel, Gas, Electricity, Temp\n",
      "2019-04-20 23:21:52,589 [INFO]  Assuming 0 string input columns: \n",
      "2019-04-20 23:21:52,593 [INFO]  No output column name provided for ColumnEncoder using Beer\n",
      "2019-04-20 23:21:52,596 [INFO]  Assuming numeric output column: Beer\n",
      "2019-04-20 23:21:52,599 [INFO]  Using [[cpu(0)]] as the context for training\n",
      "2019-04-20 23:21:52,605 [INFO]  Detected 0 rows with missing labels                         for column Beer\n",
      "2019-04-20 23:21:52,608 [INFO]  Dropping 0/364 rows\n",
      "2019-04-20 23:21:52,611 [INFO]  Detected 0 rows with missing labels                         for column Beer\n",
      "2019-04-20 23:21:52,614 [INFO]  Dropping 0/40 rows\n",
      "2019-04-20 23:21:52,617 [INFO]  Train: 364, Test: 40\n",
      "2019-04-20 23:21:52,619 [INFO]  Building Train Iterator with 364 elements\n",
      "2019-04-20 23:21:52,637 [INFO]  Concatenating numeric columns ['Car', 'Steel', 'Gas', 'Electricity', 'Temp'] into numerical_features-9ZMJLsCfMZ\n",
      "2019-04-20 23:21:52,640 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 23:21:52,646 [INFO]  Data Encoding - Encoded 365 rows of column                         Car,Steel,Gas,Electricity,Temp with <class 'datawig.column_encoders.NumericalEncoder'> into                         <class 'numpy.ndarray'> of shape (365, 5)                         and then into shape (365, 5)\n",
      "2019-04-20 23:21:52,651 [INFO]  Concatenating numeric columns ['Beer'] into Beer\n",
      "2019-04-20 23:21:52,653 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 23:21:52,657 [INFO]  Label Encoding - Encoded 365 rows of column                             Beer with <class 'datawig.column_encoders.NumericalEncoder'> into                             <class 'numpy.ndarray'> of shape (365, 1) and                             then into shape (365, 1)\n",
      "2019-04-20 23:21:52,659 [INFO]  Building Test Iterator with 40 elements\n",
      "2019-04-20 23:21:52,670 [INFO]  Concatenating numeric columns ['Car', 'Steel', 'Gas', 'Electricity', 'Temp'] into numerical_features-9ZMJLsCfMZ\n",
      "2019-04-20 23:21:52,672 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 23:21:52,676 [INFO]  Data Encoding - Encoded 40 rows of column                         Car,Steel,Gas,Electricity,Temp with <class 'datawig.column_encoders.NumericalEncoder'> into                         <class 'numpy.ndarray'> of shape (40, 5)                         and then into shape (40, 5)\n",
      "2019-04-20 23:21:52,681 [INFO]  Concatenating numeric columns ['Beer'] into Beer\n",
      "2019-04-20 23:21:52,685 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 23:21:52,690 [INFO]  Label Encoding - Encoded 40 rows of column                             Beer with <class 'datawig.column_encoders.NumericalEncoder'> into                             <class 'numpy.ndarray'> of shape (40, 1) and                             then into shape (40, 1)\n",
      "2019-04-20 23:21:52,693 [INFO]  \n",
      "========== start: fit model\n",
      "2019-04-20 23:21:52,695 [WARNING]  Already bound, ignoring bind()\n",
      "C:\\Users\\Jackie Li\\Anaconda3\\lib\\site-packages\\mxnet\\module\\base_module.py:503: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "2019-04-20 23:21:52,698 [WARNING]  optimizer already initialized, ignoring...\n",
      "2019-04-20 23:21:52,755 [INFO]  Epoch[0] Batch [0-37]\tSpeed: 3709.87 samples/sec\tcross-entropy=0.965890\tBeer-accuracy=0.000000\n",
      "2019-04-20 23:21:52,800 [INFO]  Epoch[0] Train-cross-entropy=0.934271\n",
      "2019-04-20 23:21:52,803 [INFO]  Epoch[0] Train-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:52,806 [INFO]  Epoch[0] Time cost=0.103\n",
      "2019-04-20 23:21:52,848 [INFO]  Saved checkpoint to \"imputer_model\\model-0000.params\"\n",
      "2019-04-20 23:21:52,856 [INFO]  Epoch[0] Validation-cross-entropy=1.502696\n",
      "2019-04-20 23:21:52,858 [INFO]  Epoch[0] Validation-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:52,907 [INFO]  Epoch[1] Batch [0-37]\tSpeed: 4122.24 samples/sec\tcross-entropy=0.951078\tBeer-accuracy=0.000000\n",
      "2019-04-20 23:21:52,958 [INFO]  Epoch[1] Train-cross-entropy=0.922294\n",
      "2019-04-20 23:21:52,960 [INFO]  Epoch[1] Train-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:52,962 [INFO]  Epoch[1] Time cost=0.102\n",
      "2019-04-20 23:21:52,984 [INFO]  Saved checkpoint to \"imputer_model\\model-0001.params\"\n",
      "2019-04-20 23:21:52,991 [INFO]  Epoch[1] Validation-cross-entropy=1.512594\n",
      "2019-04-20 23:21:52,993 [INFO]  Epoch[1] Validation-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:53,046 [INFO]  Epoch[2] Batch [0-37]\tSpeed: 3785.68 samples/sec\tcross-entropy=0.937715\tBeer-accuracy=0.000000\n",
      "2019-04-20 23:21:53,094 [INFO]  Epoch[2] Train-cross-entropy=0.911299\n",
      "2019-04-20 23:21:53,096 [INFO]  Epoch[2] Train-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:53,098 [INFO]  Epoch[2] Time cost=0.103\n",
      "2019-04-20 23:21:53,114 [INFO]  Saved checkpoint to \"imputer_model\\model-0002.params\"\n",
      "2019-04-20 23:21:53,123 [INFO]  Epoch[2] Validation-cross-entropy=1.523891\n",
      "2019-04-20 23:21:53,125 [INFO]  Epoch[2] Validation-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:53,178 [INFO]  Epoch[3] Batch [0-37]\tSpeed: 3785.64 samples/sec\tcross-entropy=0.924953\tBeer-accuracy=0.000000\n",
      "2019-04-20 23:21:53,224 [INFO]  Epoch[3] Train-cross-entropy=0.900580\n",
      "2019-04-20 23:21:53,226 [INFO]  Epoch[3] Train-Beer-accuracy=0.000000\n",
      "2019-04-20 23:21:53,228 [INFO]  Epoch[3] Time cost=0.102\n",
      "2019-04-20 23:21:53,251 [INFO]  Saved checkpoint to \"imputer_model\\model-0003.params\"\n",
      "2019-04-20 23:21:53,258 [INFO]  No improvement detected for 3 epochs compared to 1.5026957541704178 last error obtained: 1.525939479470253, stopping here\n",
      "2019-04-20 23:21:53,261 [INFO]  Stopping training, patience reached\n",
      "2019-04-20 23:21:53,263 [INFO]  \n",
      "========== done (0.5714719295501709 s) fit model\n",
      "2019-04-20 23:21:53,276 [INFO]  Expected calibration error: 100.0%\n",
      "2019-04-20 23:21:53,282 [INFO]  Expected calibration error after calibration: 100.0%\n",
      "2019-04-20 23:21:53,301 [INFO]  save metrics in imputer_model\\fit-test-metrics.json\n",
      "2019-04-20 23:21:53,311 [INFO]  Keeping imputer_model\\model-0000.params\n",
      "2019-04-20 23:21:53,314 [INFO]  Deleting imputer_model\\model-0001.params\n",
      "2019-04-20 23:21:53,321 [INFO]  Deleting imputer_model\\model-0002.params\n",
      "2019-04-20 23:21:53,325 [INFO]  Deleting imputer_model\\model-0003.params\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datawig.simple_imputer.SimpleImputer at 0x28ee200f6a0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_final[df_final['Beer'].notnull()], num_epochs=300,learning_rate=1e-3,batch_size=5,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-20 23:21:55,699 [INFO]  Concatenating numeric columns ['Car', 'Steel', 'Gas', 'Electricity', 'Temp'] into numerical_features-9ZMJLsCfMZ\n",
      "2019-04-20 23:21:55,701 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 23:21:55,706 [INFO]  Data Encoding - Encoded 435 rows of column                         Car,Steel,Gas,Electricity,Temp with <class 'datawig.column_encoders.NumericalEncoder'> into                         <class 'numpy.ndarray'> of shape (435, 5)                         and then into shape (435, 5)\n",
      "2019-04-20 23:21:55,711 [INFO]  Concatenating numeric columns ['Beer'] into Beer\n",
      "2019-04-20 23:21:55,714 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 23:21:55,718 [INFO]  Label Encoding - Encoded 435 rows of column                             Beer with <class 'datawig.column_encoders.NumericalEncoder'> into                             <class 'numpy.ndarray'> of shape (435, 1) and                             then into shape (435, 1)\n",
      "2019-04-20 23:21:55,776 [INFO]  Top-k only for CategoricalEncoder, dropping Beer, <class 'datawig.column_encoders.NumericalEncoder'>\n",
      "2019-04-20 23:21:55,779 [INFO]  Precision filtering only for CategoricalEncoder returning                             Beer unfiltered\n"
     ]
    }
   ],
   "source": [
    "#Impute missing values and return original dataframe with predictions\n",
    "imputed = imputer.predict(df_final)\n",
    "#imputed.to_csv('./Imputation Results/imputation_Datawig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=imputed[imputed['Beer'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198.71291211265773, 0.836286238218155)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate MSE score\n",
    "MSE = mean_squared_error(predictions['Beer'].values, predictions['Beer_imputed'].values)\n",
    "\n",
    "#Calculate r2 score\n",
    "r2=r2_score(predictions['Beer'].values, predictions['Beer_imputed'].values)\n",
    "\n",
    "MSE,r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data=imputed.copy()\n",
    "imputed_data.loc['1972-09-01':'1975-02-01','Beer']=imputed.loc['1972-09-01':'1975-02-01']['Beer_imputed'].values\n",
    "imputed_data=imputed_data.drop('Beer_imputed',axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beer</th>\n",
       "      <th>Car</th>\n",
       "      <th>Steel</th>\n",
       "      <th>Gas</th>\n",
       "      <th>Electricity</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956-01-01</th>\n",
       "      <td>93.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.9</td>\n",
       "      <td>1709</td>\n",
       "      <td>1254</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-02-01</th>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.1</td>\n",
       "      <td>1646</td>\n",
       "      <td>1290</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-03-01</th>\n",
       "      <td>95.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.8</td>\n",
       "      <td>1794</td>\n",
       "      <td>1379</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-04-01</th>\n",
       "      <td>77.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.9</td>\n",
       "      <td>1878</td>\n",
       "      <td>1346</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-05-01</th>\n",
       "      <td>70.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2173</td>\n",
       "      <td>1535</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Beer  Car  Steel   Gas  Electricity  Temp\n",
       "Date                                                 \n",
       "1956-01-01  93.2  NaN  196.9  1709         1254  25.1\n",
       "1956-02-01  96.0  NaN  192.1  1646         1290  25.3\n",
       "1956-03-01  95.2  NaN  201.8  1794         1379  24.9\n",
       "1956-04-01  77.1  NaN  186.9  1878         1346  23.9\n",
       "1956-05-01  70.9  NaN  218.0  2173         1535  19.4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['Beer','Steel','Gas','Electricity','Temp'], # column(s) containing information about the column we want to impute\n",
    "    output_column='Car', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-20 22:44:42,708 [INFO]  Assuming 5 numeric input columns: Beer, Steel, Gas, Electricity, Temp\n",
      "2019-04-20 22:44:42,710 [INFO]  Assuming 0 string input columns: \n",
      "2019-04-20 22:44:42,712 [INFO]  No output column name provided for ColumnEncoder using Car\n",
      "2019-04-20 22:44:42,713 [INFO]  Assuming numeric output column: Car\n",
      "2019-04-20 22:44:42,715 [INFO]  Using [[cpu(0)]] as the context for training\n",
      "2019-04-20 22:44:42,720 [INFO]  Fitting label encoder <class 'datawig.column_encoders.NumericalEncoder'> on 332 rows                             of training data\n",
      "2019-04-20 22:44:42,728 [INFO]  Detected 0 rows with missing labels                         for column Car\n",
      "2019-04-20 22:44:42,730 [INFO]  Dropping 0/332 rows\n",
      "2019-04-20 22:44:42,733 [INFO]  Detected 0 rows with missing labels                         for column Car\n",
      "2019-04-20 22:44:42,735 [INFO]  Dropping 0/36 rows\n",
      "2019-04-20 22:44:42,738 [INFO]  Train: 332, Test: 36\n",
      "2019-04-20 22:44:42,739 [INFO]  Fitting data encoder <class 'datawig.column_encoders.NumericalEncoder'> on columns Beer, Steel, Gas, Electricity, Temp and 332 rows of training data with parameters {'input_columns': ['Beer', 'Steel', 'Gas', 'Electricity', 'Temp'], 'output_column': 'numerical_features-BuNO6n9JEC', 'output_dim': 5, 'normalize': True, 'scaler': None}\n",
      "2019-04-20 22:44:42,750 [INFO]  Building Train Iterator with 332 elements\n",
      "2019-04-20 22:44:42,767 [INFO]  Concatenating numeric columns ['Beer', 'Steel', 'Gas', 'Electricity', 'Temp'] into numerical_features-BuNO6n9JEC\n",
      "2019-04-20 22:44:42,768 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 22:44:42,773 [INFO]  Data Encoding - Encoded 336 rows of column                         Beer,Steel,Gas,Electricity,Temp with <class 'datawig.column_encoders.NumericalEncoder'> into                         <class 'numpy.ndarray'> of shape (336, 5)                         and then into shape (336, 5)\n",
      "2019-04-20 22:44:42,778 [INFO]  Concatenating numeric columns ['Car'] into Car\n",
      "2019-04-20 22:44:42,779 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 22:44:42,782 [INFO]  Label Encoding - Encoded 336 rows of column                             Car with <class 'datawig.column_encoders.NumericalEncoder'> into                             <class 'numpy.ndarray'> of shape (336, 1) and                             then into shape (336, 1)\n",
      "2019-04-20 22:44:42,783 [INFO]  Building Test Iterator with 36 elements\n",
      "2019-04-20 22:44:42,816 [INFO]  Concatenating numeric columns ['Beer', 'Steel', 'Gas', 'Electricity', 'Temp'] into numerical_features-BuNO6n9JEC\n",
      "2019-04-20 22:44:42,817 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 22:44:42,820 [INFO]  Data Encoding - Encoded 48 rows of column                         Beer,Steel,Gas,Electricity,Temp with <class 'datawig.column_encoders.NumericalEncoder'> into                         <class 'numpy.ndarray'> of shape (48, 5)                         and then into shape (48, 5)\n",
      "2019-04-20 22:44:42,823 [INFO]  Concatenating numeric columns ['Car'] into Car\n",
      "2019-04-20 22:44:42,825 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 22:44:42,829 [INFO]  Label Encoding - Encoded 48 rows of column                             Car with <class 'datawig.column_encoders.NumericalEncoder'> into                             <class 'numpy.ndarray'> of shape (48, 1) and                             then into shape (48, 1)\n",
      "2019-04-20 22:44:42,831 [INFO]  Concatenating all 1 latent symbols\n",
      "2019-04-20 22:44:42,832 [INFO]  Constructing numerical loss for column Car\n",
      "2019-04-20 22:44:42,835 [INFO]  Building output symbols\n",
      "2019-04-20 22:44:42,840 [INFO]  \n",
      "========== start: fit model\n",
      "2019-04-20 22:44:42,842 [WARNING]  Already bound, ignoring bind()\n",
      "2019-04-20 22:44:42,870 [INFO]  Epoch[0] Batch [0-11]\tSpeed: 8823.68 samples/sec\tcross-entropy=14.443293\tCar-accuracy=0.000000\n",
      "2019-04-20 22:44:42,886 [INFO]  Epoch[0] Train-cross-entropy=13.688891\n",
      "2019-04-20 22:44:42,888 [INFO]  Epoch[0] Train-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:42,890 [INFO]  Epoch[0] Time cost=0.043\n",
      "2019-04-20 22:44:42,909 [INFO]  Saved checkpoint to \"imputer_model\\model-0000.params\"\n",
      "2019-04-20 22:44:42,914 [INFO]  Epoch[0] Validation-cross-entropy=10.143172\n",
      "2019-04-20 22:44:42,916 [INFO]  Epoch[0] Validation-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:42,940 [INFO]  Epoch[1] Batch [0-11]\tSpeed: 8403.51 samples/sec\tcross-entropy=10.389826\tCar-accuracy=0.000000\n",
      "2019-04-20 22:44:42,960 [INFO]  Epoch[1] Train-cross-entropy=10.606893\n",
      "2019-04-20 22:44:42,962 [INFO]  Epoch[1] Train-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:42,963 [INFO]  Epoch[1] Time cost=0.046\n",
      "2019-04-20 22:44:42,978 [INFO]  Saved checkpoint to \"imputer_model\\model-0001.params\"\n",
      "2019-04-20 22:44:42,984 [INFO]  Epoch[1] Validation-cross-entropy=10.206568\n",
      "2019-04-20 22:44:42,985 [INFO]  Epoch[1] Validation-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:43,006 [INFO]  Epoch[2] Batch [0-11]\tSpeed: 9804.33 samples/sec\tcross-entropy=9.709803\tCar-accuracy=0.000000\n",
      "2019-04-20 22:44:43,022 [INFO]  Epoch[2] Train-cross-entropy=10.107667\n",
      "2019-04-20 22:44:43,024 [INFO]  Epoch[2] Train-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:43,027 [INFO]  Epoch[2] Time cost=0.041\n",
      "2019-04-20 22:44:43,048 [INFO]  Saved checkpoint to \"imputer_model\\model-0002.params\"\n",
      "2019-04-20 22:44:43,053 [INFO]  Epoch[2] Validation-cross-entropy=10.667156\n",
      "2019-04-20 22:44:43,055 [INFO]  Epoch[2] Validation-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:43,077 [INFO]  Epoch[3] Batch [0-11]\tSpeed: 9810.06 samples/sec\tcross-entropy=9.548476\tCar-accuracy=0.000000\n",
      "2019-04-20 22:44:43,094 [INFO]  Epoch[3] Train-cross-entropy=9.943596\n",
      "2019-04-20 22:44:43,095 [INFO]  Epoch[3] Train-Car-accuracy=0.000000\n",
      "2019-04-20 22:44:43,096 [INFO]  Epoch[3] Time cost=0.040\n",
      "2019-04-20 22:44:43,113 [INFO]  Saved checkpoint to \"imputer_model\\model-0003.params\"\n",
      "2019-04-20 22:44:43,118 [INFO]  No improvement detected for 3 epochs compared to 10.143171866734823 last error obtained: 11.033910592397055, stopping here\n",
      "2019-04-20 22:44:43,119 [INFO]  Stopping training, patience reached\n",
      "2019-04-20 22:44:43,121 [INFO]  \n",
      "========== done (0.2812483310699463 s) fit model\n",
      "2019-04-20 22:44:43,129 [INFO]  Expected calibration error: 100.0%\n",
      "2019-04-20 22:44:43,136 [INFO]  Expected calibration error after calibration: 100.0%\n",
      "2019-04-20 22:44:43,144 [INFO]  save metrics in imputer_model\\fit-test-metrics.json\n",
      "2019-04-20 22:44:43,155 [INFO]  Keeping imputer_model\\model-0000.params\n",
      "2019-04-20 22:44:43,157 [INFO]  Deleting imputer_model\\model-0001.params\n",
      "2019-04-20 22:44:43,161 [INFO]  Deleting imputer_model\\model-0002.params\n",
      "2019-04-20 22:44:43,164 [INFO]  Deleting imputer_model\\model-0003.params\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datawig.simple_imputer.SimpleImputer at 0x28edbbe9860>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=imputed_data[imputed_data['Car'].notnull()], num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-20 22:44:56,438 [INFO]  Concatenating numeric columns ['Beer', 'Steel', 'Gas', 'Electricity', 'Temp'] into numerical_features-BuNO6n9JEC\n",
      "2019-04-20 22:44:56,439 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 22:44:56,443 [INFO]  Data Encoding - Encoded 448 rows of column                         Beer,Steel,Gas,Electricity,Temp with <class 'datawig.column_encoders.NumericalEncoder'> into                         <class 'numpy.ndarray'> of shape (448, 5)                         and then into shape (448, 5)\n",
      "2019-04-20 22:44:56,448 [INFO]  Concatenating numeric columns ['Car'] into Car\n",
      "2019-04-20 22:44:56,451 [INFO]  Normalizing with StandardScaler\n",
      "2019-04-20 22:44:56,454 [INFO]  Label Encoding - Encoded 448 rows of column                             Car with <class 'datawig.column_encoders.NumericalEncoder'> into                             <class 'numpy.ndarray'> of shape (448, 1) and                             then into shape (448, 1)\n",
      "2019-04-20 22:44:56,472 [INFO]  Top-k only for CategoricalEncoder, dropping Car, <class 'datawig.column_encoders.NumericalEncoder'>\n",
      "2019-04-20 22:44:56,473 [INFO]  Precision filtering only for CategoricalEncoder returning                             Car unfiltered\n"
     ]
    }
   ],
   "source": [
    "#Impute missing values and return original dataframe with predictions\n",
    "imputed_car = imputer.predict(imputed_data)\n",
    "#imputed.to_csv('./Imputation Results/imputation_Datawig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_final=imputed_car.copy()\n",
    "imputed_data_final.loc['1956-01-01':'1961-06-01','Car']=\\\n",
    "imputed_car.loc['1956-01-01':'1961-06-01']['Car_imputed'].values\n",
    "imputed_data_final=imputed_data_final.drop('Car_imputed',axis=1)\n",
    "imputed_data_final.to_csv('data_merged_final.csv');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
